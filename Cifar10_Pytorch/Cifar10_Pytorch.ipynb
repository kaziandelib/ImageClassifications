{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if needed\n",
        "#!pip install numpy\n",
        "#!pip install pillow\n",
        "#!pip install torch\n",
        "#!pip install torchvision"
      ],
      "metadata": {
        "id": "v7KFRnkORAY9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To import necessary libraries\n",
        "import numpy as np  # Library for numerical computations, especially with arrays\n",
        "import torch  # Main PyTorch library for tensor operations\n",
        "import torch.nn as nn  # Submodule of PyTorch for building neural network layers and structures\n",
        "import torch.nn.functional as F  # Functional interface for various neural network operations (like activation functions)\n",
        "import torch.optim as optim  # Submodule for optimization algorithms (e.g., SGD, Adam)\n",
        "import torchvision  # Library that provides tools for image datasets and transformations\n",
        "import torchvision.transforms as transforms  # Module for applying transformations to image datasets\n",
        "import matplotlib.pyplot as plt  # Library for plotting and visualizing data\n",
        "import urllib.request  # Module for opening and reading URLs\n",
        "from PIL import Image  # Python Imaging Library for opening, manipulating, and saving image files\n"
      ],
      "metadata": {
        "id": "v6q11XF8RAcF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To create a series of transformations to be applied to images\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),  # To convert the image to a PyTorch tensor (scales pixel values to [0, 1])\n",
        "        # To normalize the tensor to have a mean of 0.5 and standard deviation of 0.5 for each color channel (RGB)\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ndgSvldIRAie"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the CIFAR-10 dataset for training\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # To specify the directory where the dataset will be stored\n",
        "    train=True,     # To indicate that this is the training dataset\n",
        "    download=True,  # To download the dataset if it is not already available in the specified directory\n",
        "    transform=transform  # To apply the defined transformations (e.g., ToTensor, Normalize) to the images\n",
        ")\n",
        "\n",
        "# To load the CIFAR-10 dataset for testing\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # To specify the directory for the dataset\n",
        "    train=False,    # To indicate that this is the testing dataset\n",
        "    download=True,  # To download the dataset if it is not already available\n",
        "    transform=transform  # To apply the same transformations to the test images\n",
        ")\n",
        "\n",
        "# To create a DataLoader for the training dataset to facilitate batch processing\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,      # The dataset to load\n",
        "    batch_size=32,   # To specify the number of samples per batch\n",
        "    shuffle=True,    # To shuffle the data at every epoch to ensure randomness\n",
        "    num_workers=2    # To use 2 subprocesses for data loading to improve efficiency\n",
        ")\n",
        "\n",
        "# To create a DataLoader for the testing dataset\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,       # The dataset to load\n",
        "    batch_size=32,   # To specify the number of samples per batch\n",
        "    shuffle=True,    # To shuffle the data to ensure randomness during testing\n",
        "    num_workers=2    # To use 2 subprocesses for data loading\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRHDCKPfTAta",
        "outputId": "4ba05b0e-cb2b-4d71-9124-3be30a5e113f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To retrieve the first image and its corresponding label from the training dataset\n",
        "image, label = train_data[0]  # 'train_data' is the CIFAR-10 dataset; this fetches the first item (image-label pair)\n",
        "\n",
        "# To get the size of the retrieved image tensor\n",
        "image.size()  # This will return the dimensions of the image tensor (e.g., [channels, height, width])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni17QqTpTAqD",
        "outputId": "8804b4f3-4336-4a78-db45-5461530e952a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To define a list of class names corresponding to the labels in the CIFAR-10 dataset\n",
        "class_names = [\n",
        "    'plane',  # Class 0: airplane\n",
        "    'car',    # Class 1: automobile\n",
        "    'bird',   # Class 2: bird\n",
        "    'cat',    # Class 3: cat\n",
        "    'deer',   # Class 4: deer\n",
        "    'dog',    # Class 5: dog\n",
        "    'frog',   # Class 6: frog\n",
        "    'horse',  # Class 7: horse\n",
        "    'ship',   # Class 8: ship\n",
        "    'truck'   # Class 9: truck\n",
        "]"
      ],
      "metadata": {
        "id": "xp7yOskHTAnT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display a set of images with their corresponding labels\n",
        "def show_images(images, labels):\n",
        "    # To create a figure with subplots; one for each image\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 3))  # 1 row, 'len(images)' columns\n",
        "\n",
        "    # To iterate through images, labels, and axes for plotting\n",
        "    for img, label, ax in zip(images, labels, axes):\n",
        "        # To convert the image tensor to a NumPy array, transpose dimensions, and undo normalization for display\n",
        "        ax.imshow(np.transpose(img.numpy(), (1, 2, 0)) * 0.5 + 0.5)\n",
        "        # To set the title of each subplot to the corresponding class name\n",
        "        ax.set_title(class_names[label])\n",
        "        # To turn off the axis for better visual presentation\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    # To show the figure with the images\n",
        "    plt.show()\n",
        "\n",
        "# To get an iterator for the training data loader\n",
        "data_iter = iter(train_loader)\n",
        "\n",
        "# To retrieve a batch of images and their corresponding labels from the training data\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# To display the first 5 images and their labels in the batch using the show_images function\n",
        "show_images(images[:5], labels[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "XYiPKlUhfrbA",
        "outputId": "d0d48093-4a66-49c1-ac75-fbb71bb759dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To define a neural network class that inherits from nn.Module\n",
        "class NeuralNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        # To initialize the parent class\n",
        "        super().__init__()\n",
        "\n",
        "        # First convolutional layer: takes 3 input channels (RGB), outputs 12 channels, with a 5x5 kernel\n",
        "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
        "\n",
        "        # Max pooling layer: reduces the spatial dimensions by a factor of 2 (2x2 pooling)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Second convolutional layer: takes 12 input channels, outputs 24 channels, with a 5x5 kernel\n",
        "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
        "\n",
        "        # To define fully connected layers:\n",
        "        # First fully connected layer: flattens the output of the last convolutional layer\n",
        "        # 24 channels, each 5x5 spatial dimensions, results in 24 * 5 * 5 = 600 inputs to this layer\n",
        "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
        "\n",
        "        # Second fully connected layer: takes 120 inputs and outputs 96\n",
        "        self.fc2 = nn.Linear(120, 98)\n",
        "\n",
        "        # Third fully connected layer: takes 96 inputs and outputs 10 (number of classes in CIFAR-10)\n",
        "        self.fc3 = nn.Linear(98, 10)\n",
        "\n",
        "    # To define the forward pass through the network\n",
        "    def forward(self, x):\n",
        "        # Apply the first convolutional layer, followed by ReLU activation, and then max pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # To apply the second convolutional layer, followed by ReLU activation, and then max pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # To flatten the tensor to feed into the fully connected layers (batch size remains)\n",
        "        x = torch.flatten(x, 1)  # To flatten all dimensions except batch\n",
        "\n",
        "        # To apply the first fully connected layer, followed by ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # To apply the second fully connected layer, followed by ReLU activation\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # To apply the third fully connected layer (final output layer)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # To return the output of the network (logits for each class)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oH-JfVz4cl-d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To instantiate the neural network model\n",
        "net = NeuralNet()  # To create an instance of the NeuralNet class defined earlier\n",
        "\n",
        "# To define the loss function for multi-class classification\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# This loss function combines softmax and negative log-likelihood loss, suitable for classification tasks\n",
        "\n",
        "# To set up the optimizer for updating the model's weights\n",
        "optimizer = optim.SGD(\n",
        "    net.parameters(),  # To pass the parameters of the neural network to the optimizer\n",
        "    lr=0.001,         # Learning rate: controls how much to adjust the weights during optimization\n",
        "    momentum=0.9      # Momentum: helps accelerate gradients vectors in the right directions, improving convergence speed\n",
        ")\n"
      ],
      "metadata": {
        "id": "scLJZz61UTFB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To train the neural network for a specified number of epochs\n",
        "for epoch in range(40):  # To loop over the dataset multiple times (32 epochs)\n",
        "    print(f'Training epoch {epoch}...')  # To print the current epoch number\n",
        "    running_loss = 0.0  # To initialize the total loss for this epoch\n",
        "\n",
        "    # To iterate over the training data loader\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data  # To get the inputs (images) and labels (targets) from the current batch\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients of the model parameters to prevent accumulation\n",
        "        outputs = net(inputs)  # Forward pass: compute predicted outputs by passing inputs through the network\n",
        "\n",
        "        loss = loss_function(outputs, labels)  # To compute the loss by comparing outputs to the true labels\n",
        "        loss.backward()  # Backward pass: compute gradients of the loss with respect to model parameters\n",
        "        optimizer.step()  # To update model parameters using the computed gradients\n",
        "\n",
        "        running_loss += loss.item()  # To accumulate the loss for the current batch\n",
        "\n",
        "    # To print the average loss for the epoch (total loss divided by number of batches)\n",
        "    print(f'Loss: {running_loss/len(train_loader):.5f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_AD2DUiUTBr",
        "outputId": "92eb356e-4493-4314-c062-8e3b8bedb3fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 0...\n",
            "Loss: 2.22947\n",
            "Training epoch 1...\n",
            "Loss: 1.77593\n",
            "Training epoch 2...\n",
            "Loss: 1.51207\n",
            "Training epoch 3...\n",
            "Loss: 1.38509\n",
            "Training epoch 4...\n",
            "Loss: 1.28635\n",
            "Training epoch 5...\n",
            "Loss: 1.20962\n",
            "Training epoch 6...\n",
            "Loss: 1.14193\n",
            "Training epoch 7...\n",
            "Loss: 1.07888\n",
            "Training epoch 8...\n",
            "Loss: 1.03233\n",
            "Training epoch 9...\n",
            "Loss: 0.98530\n",
            "Training epoch 10...\n",
            "Loss: 0.94475\n",
            "Training epoch 11...\n",
            "Loss: 0.90618\n",
            "Training epoch 12...\n",
            "Loss: 0.86676\n",
            "Training epoch 13...\n",
            "Loss: 0.83527\n",
            "Training epoch 14...\n",
            "Loss: 0.80164\n",
            "Training epoch 15...\n",
            "Loss: 0.77282\n",
            "Training epoch 16...\n",
            "Loss: 0.74045\n",
            "Training epoch 17...\n",
            "Loss: 0.71573\n",
            "Training epoch 18...\n",
            "Loss: 0.66435\n",
            "Training epoch 20...\n",
            "Loss: 0.63468\n",
            "Training epoch 21...\n",
            "Loss: 0.61173\n",
            "Training epoch 22...\n",
            "Loss: 0.58985\n",
            "Training epoch 23...\n",
            "Loss: 0.56355\n",
            "Training epoch 24...\n",
            "Loss: 0.53768\n",
            "Training epoch 25...\n",
            "Loss: 0.52102\n",
            "Training epoch 26...\n",
            "Loss: 0.49632\n",
            "Training epoch 27...\n",
            "Loss: 0.47413\n",
            "Training epoch 28...\n",
            "Loss: 0.45441\n",
            "Training epoch 29...\n",
            "Loss: 0.43521\n",
            "Training epoch 30...\n",
            "Loss: 0.41365\n",
            "Training epoch 31...\n",
            "Loss: 0.39655\n",
            "Training epoch 32...\n",
            "Loss: 0.37801\n",
            "Training epoch 33...\n",
            "Loss: 0.35896\n",
            "Training epoch 34...\n",
            "Loss: 0.34108\n",
            "Training epoch 35...\n",
            "Loss: 0.32059\n",
            "Training epoch 36...\n",
            "Loss: 0.30901\n",
            "Training epoch 37...\n",
            "Loss: 0.28967\n",
            "Training epoch 38...\n",
            "Loss: 0.27798\n",
            "Training epoch 39...\n",
            "Loss: 0.26262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To save the trained model's state dictionary (weights and biases)\n",
        "torch.save(net.state_dict(), 'trained_net.pth')\n",
        "# 'net.state_dict()' retrieves the model parameters (weights and biases) for all layers\n",
        "# 'trained_net.pth' is the filename where the model parameters will be saved\n",
        "# This file can be used later to load the model for inference or further training"
      ],
      "metadata": {
        "id": "aKuT1vnvjm7Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To instantiate a new instance of the NeuralNet model\n",
        "net = NeuralNet()\n",
        "\n",
        "# To load the previously saved model parameters (weights and biases) into the neural network\n",
        "net.load_state_dict(torch.load('trained_net.pth'))\n",
        "# 'torch.load()' reads the saved state dictionary from the specified file ('trained_net.pth')\n",
        "# 'load_state_dict()' updates the model with the loaded parameters, allowing the model to be used for inference or further training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LIF6I7XjqgD",
        "outputId": "02a0017a-c728-4efa-818a-7ef3b108a332"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-dd3aafea2970>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load('trained_net.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To initialize counters for correct predictions and total number of samples\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# To set the model to evaluation mode (disables dropout and batch normalization)\n",
        "net.eval()\n",
        "\n",
        "# To disable gradient computation for inference to reduce memory consumption and improve speed\n",
        "with torch.no_grad():\n",
        "    # To iterate over the test data loader\n",
        "    for data in test_loader:\n",
        "        images, labels = data  # To get the images and corresponding labels from the test batch\n",
        "\n",
        "        # Forward pass: compute predicted outputs by passing images through the network\n",
        "        outputs = net(images)\n",
        "\n",
        "        # To get the predicted class by finding the index of the maximum log-probability\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # To update the total count of samples processed\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # To count the number of correct predictions by comparing predicted and true labels\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# To calculate the accuracy as the percentage of correctly predicted samples\n",
        "accuracy = 100 * correct / total\n",
        "\n",
        "# To print the accuracy of the model on the test dataset\n",
        "print(f'Accuracy: {accuracy}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay5dT1Oxjqcp",
        "outputId": "e83c3369-3e74-48e2-d707-ed86252c465c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 66.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To define URLs for images to be predicted\n",
        "url1 = \"https://images.pexels.com/photos/1170986/pexels-photo-1170986.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1\"  # URL for a cat image\n",
        "url2 = \"https://images.pexels.com/photos/46148/aircraft-jet-landing-cloud-46148.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1\"  # URL for a plane image\n",
        "url3 = \"https://images.pexels.com/photos/825947/pexels-photo-825947.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1\"  # URL for a dog image\n",
        "\n",
        "# To define a transform to preprocess the images before passing them to the model\n",
        "new_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # To resize the image to 32x32 pixels to match the input size of the model\n",
        "    transforms.ToTensor(),          # To convert the image to a PyTorch tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # To normalize the image with mean and std deviation\n",
        "])\n",
        "\n",
        "def load_img(image_url):\n",
        "    # To set up a request with a user-agent header to avoid blocking\n",
        "    req = urllib.request.Request(image_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    with urllib.request.urlopen(req) as url_response:  # To open the URL and retrieve the image\n",
        "        image = Image.open(url_response)  # To open the image from the URL response\n",
        "        image = new_transform(image)  # To apply the defined transformations to the image\n",
        "        image = image.unsqueeze(0)  # To add a batch dimension (1, 3, 32, 32) for the model input\n",
        "    return image  # To aeturn the preprocessed image\n",
        "\n",
        "# To create a list of image URLs to be predicted\n",
        "image_paths = [url1, url2, url3]  # To add URLs as needed\n",
        "images = [load_img(img) for img in image_paths]  # To load and preprocess each image URL\n",
        "\n",
        "# To set the model to evaluation mode (disables dropout and batch normalization)\n",
        "net.eval()\n",
        "with torch.no_grad():  # To disable gradient computation for inference\n",
        "    # To iterate through the preprocessed images\n",
        "    for image in images:\n",
        "        output = net(image)  # Forward pass: get the model's output for the image\n",
        "        _, predicted = torch.max(output, 1)  # To get the predicted class index with the highest score\n",
        "        # To print the predicted class name based on the predicted index\n",
        "        print(f\"Prediction: {class_names[predicted.item()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyOisZ7QoPFx",
        "outputId": "6ba91b88-82e6-4176-92fa-2e52864f8807"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: truck\n",
            "Prediction: plane\n",
            "Prediction: dog\n"
          ]
        }
      ]
    }
  ]
}